{
  "issues": [
    {
      "title": "Harden Terraform IAM: replace admin/owner roles and review public artifact access",
      "kind": "Non-standard/antipatterns",
      "files": [
        {
          "path": "terraform/modules/ci/main.tf"
        },
        {
          "path": "terraform/platform/main.tf"
        },
        {
          "path": "terraform/global/main.tf"
        }
      ],
      "short_description": "**Goal**: Reduce blast radius of CI and platform identities and ensure public access is intentional.\n\n**Why it matters**\n- CI and platform Terraform currently grant very broad roles (`roles/admin`, `roles/owner`) and public read access to an artifact registry. A misconfiguration or compromise could impact the entire GCP project.\n\n**Scope & files**\n- `terraform/modules/ci/main.tf`\n  - `google_project_iam_member.github_service_account` with `role = \"roles/admin\"`.\n- `terraform/platform/main.tf`\n  - `google_project_iam_member.owner_groups` with `role = \"roles/owner\"`.\n- `terraform/global/main.tf`\n  - `google_artifact_registry_repository_iam_binding.public_read` with `members = [\"allUsers\"]`.\n  - `google_storage_bucket_iam_member.site_state` with a hard-coded GitHub Actions service account email.\n\n**Concrete actions**\n1. **CI service account (roles/admin \u2192 least privilege)**\n   - Open `terraform/modules/ci/main.tf`.\n   - Identify what CI pipelines actually need to do (build/push images, apply Terraform, run tests, etc.).\n   - Replace:\n     ```hcl\n     resource \"google_project_iam_member\" \"github_service_account\" {\n       project = var.project\n       role    = \"roles/admin\"\n       member  = google_service_account.github_actions.member\n     }\n     ```\n     with a minimal set of role bindings, for example (adapt as needed):\n     ```hcl\n     # Example \u2013 adjust to real CI needs\n     resource \"google_project_iam_member\" \"github_sa_artifact_writer\" {\n       project = var.project\n       role    = \"roles/artifactregistry.writer\"\n       member  = google_service_account.github_actions.member\n     }\n\n     resource \"google_project_iam_member\" \"github_sa_storage_admin\" {\n       project = var.project\n       role    = \"roles/storage.admin\" # or storage.objectAdmin if enough\n       member  = google_service_account.github_actions.member\n     }\n\n     resource \"google_project_iam_member\" \"github_sa_tf_state\" {\n       project = var.project\n       role    = \"roles/storage.objectAdmin\"\n       member  = google_service_account.github_actions.member\n     }\n     ```\n   - Run `terraform plan` in the CI module workspace and verify only IAM bindings change.\n\n2. **Project owner group (roles/owner \u2192 narrower roles)**\n   - Open `terraform/platform/main.tf` and find `google_project_iam_member.owner_groups`.\n   - Replace `role = \"roles/owner\"` with a set of more specific roles (e.g. `roles/editor`, `roles/iam.securityAdmin`, `roles/storage.admin`, etc.) that reflect how owners are expected to work.\n   - Split into multiple `google_project_iam_member` resources as needed.\n\n3. **Public artifact registry access**\n   - Open `terraform/global/main.tf` and locate `google_artifact_registry_repository_iam_binding.public_read`.\n   - Confirm the repository is *intended* to be public:\n     - If **yes**, add a comment explaining why public access is required and ensure only the intended repository is public.\n     - If **no**, remove that resource or restrict `members` to a controlled group/service account instead of `allUsers`.\n\n4. **Hard-coded service account in storage IAM**\n   - In `terraform/global/main.tf`, find `google_storage_bucket_iam_member.site_state` where `member` embeds a specific service account email.\n   - Replace with a data source or module output:\n     ```hcl\n     data \"google_service_account\" \"site_github_actions\" {\n       account_id = \"github-actions\"\n       project    = var.site_project\n     }\n\n     resource \"google_storage_bucket_iam_member\" \"site_state\" {\n       bucket = google_storage_bucket.state_bucket.name\n       role   = \"roles/storage.objectAdmin\" # or narrower\n       member = \"serviceAccount:${data.google_service_account.site_github_actions.email}\"\n     }\n     ```\n\n**Kind**: Non-standard/antipatterns",
      "recommended_action": ""
    },
    {
      "title": "Decouple Terraform from hard\u2011coded projects and state buckets",
      "kind": "Non-standard/antipatterns",
      "files": [
        {
          "path": "terraform/config/dev.tfvars"
        },
        {
          "path": "terraform/config/prod.tfvars"
        },
        {
          "path": "terraform/config/staging.tfvars"
        },
        {
          "path": "terraform/config/global.tfvars"
        },
        {
          "path": "terraform/global/config/backend.tfvars"
        },
        {
          "path": "terraform/site/config/global.tfvars"
        },
        {
          "path": "terraform/site/config/backend.tfvars"
        }
      ],
      "short_description": "**Goal**: Make Terraform configs reusable across environments and reduce the risk of accidentally pointing at the wrong project/state bucket.\n\n**Why it matters**\n- Multiple `.tfvars` and backend config files hard-code project IDs, regions, and state buckets (e.g. `volary-dev`, `volary-prod`, `volary-state`). This couples the repo to specific environments and increases risk when creating new environments.\n\n**Scope & examples**\n- `terraform/config/dev.tfvars`, `terraform/config/prod.tfvars`, `terraform/config/staging.tfvars`\n  - e.g. `project = \"volary-dev\"`.\n- `terraform/config/global.tfvars`\n  - e.g. `region = \"europe-west4\"`, `bucket = \"volary-state\"`.\n- `terraform/site/config/global.tfvars`\n  - e.g. `project = \"volary-site\"`.\n- `terraform/global/config/backend.tfvars`, `terraform/site/config/backend.tfvars`\n  - e.g. `bucket = \"volary-state\"`, fixed `prefix`.\n\n**Concrete actions**\n1. **Move sensitive / env-specific tfvars out of the repo or make them templates**\n   - For each `terraform/config/*.tfvars` and `terraform/*/config/*.tfvars` containing real project IDs or bucket names:\n     - Create a `*.tfvars.example` or `*.tfvars.tpl` with placeholder values:\n       ```hcl\n       project = \"<gcp-project-id>\"\n       region  = \"<gcp-region>\"\n       bucket  = \"<terraform-state-bucket>\"\n       ```\n     - Remove the real tfvars from version control (or replace contents with non-sensitive placeholders) and add them to `.gitignore`.\n   - Update README/infra docs to explain how to create real tfvars locally or in CI.\n\n2. **Parameterize backend config**\n   - For `terraform/global/config/backend.tfvars` and `terraform/site/config/backend.tfvars`:\n     - Replace hard-coded bucket names with placeholders in an example file, and ensure real values are injected by CI or per-environment configuration.\n     - Consider adding an environment prefix to `prefix`, e.g. `prefix = \"${env}/global\"` if you use workspaces or env vars.\n\n3. **Ensure CI passes the right tfvars**\n   - Update the Terraform invocation in CI (e.g., `.github/workflows/*.yml` if present) to pass environment-specific tfvars via `-var-file` pointing to non-committed tfvars or to use workspace-based variables.\n\n4. **Optional: add validation for project/region**\n   - Add input variable validation in top-level `variables.tf` (e.g. `validation` blocks checking allowed region patterns) to catch misconfigurations early.\n\n**Kind**: Non-standard/antipatterns",
      "recommended_action": ""
    },
    {
      "title": "Centralize resource validation + IAM authorization checks across API, files, and logs services",
      "kind": "Duplicate code",
      "files": [
        {
          "path": "files/v0/v0.go"
        },
        {
          "path": "logs/v0/v0.go"
        },
        {
          "path": "api/v0/json.go"
        },
        {
          "path": "common/iam"
        },
        {
          "path": "common/api"
        }
      ],
      "short_description": "**Goal**: Remove duplicated authorization/validation logic and make permission checks consistent.\n\n**Why it matters**\n- Several services repeat very similar logic:\n  - Parse a resource path or public ref\n  - Validate it (e.g. `ValidatePublicResourceRef`)\n  - Map storage/IAM errors into HTTP status codes via `api.WithHTTPCode`\n  - Call `IAM.Check` and sometimes attach org ID info to context\n- This is currently implemented independently in multiple packages, which increases the chance of drift and bugs.\n\n**Scope & files**\n- `files/v0/v0.go`\n  - `checkResourceAuth(...)` and custom error-to-status mapping.\n- `logs/v0/v0.go`\n  - `checkResourceAuth(...)` with similar logic.\n- `api/v0/json.go`\n  - `checkRouteAuth(...)` performs route-based resource parsing + IAM checks.\n- New shared helper should live in:\n  - `common/iam` or `common/api` (e.g. `common/iam/helpers.go` or `common/api/auth_helpers.go`).\n\n**Concrete actions**\n1. **Design a shared helper API**\n   - Add a helper such as:\n     ```go\n     // In common/iam or common/api\n     type ResourceChecker interface {\n       ValidatePublicResourceRef(ctx context.Context, path string) (model.PublicResourceRef, error)\n       Check(ctx context.Context, subject model.ResourceRef, action iam.Action, resource model.ResourceRef) error\n     }\n\n     func ValidateAndCheckPublicRef(\n       ctx context.Context,\n       checker ResourceChecker,\n       path string,\n       action iam.Action,\n     ) (context.Context, model.PublicResourceRef, error) {\n       // 1) validate ref, 2) map errors to api.WithHTTPCode, 3) run IAM.Check,\n       // 4) optionally attach org ID to context.\n     }\n     ```\n   - Or split into two helpers: one for validation/error-mapping, one for IAM checks.\n\n2. **Refactor `files/v0/v0.go`**\n   - Replace the body of `checkResourceAuth(...)` with a call to the shared helper.\n   - Ensure it still attaches the org ID to context if callers rely on that (e.g., use a callback or return a context with org info stored under a common key).\n\n3. **Refactor `logs/v0/v0.go`**\n   - Similarly, replace `checkResourceAuth(...)` with the shared helper, updating call sites accordingly.\n\n4. **Refactor `api/v0/json.go`**\n   - Where it currently parses the resource route and runs IAM checks, route that through the shared helper (or at least through the same validation + error-mapping functions).\n\n5. **Add tests for the new helper**\n   - In `common/iam` or `common/api`, create tests that:\n     - Simulate `ValidatePublicResourceRef` returning not-found / bad-request / success and assert correct mapping to HTTP codes via `api.WithHTTPCode`.\n     - Ensure IAM denial propagates as the appropriate error.\n   - Run existing tests for `api/v0`, `files/v0`, and `logs/v0` to confirm behavior is preserved.\n\n**Kind**: Duplicate code",
      "recommended_action": ""
    },
    {
      "title": "Unify HTTP handler registration and error mapping for streaming endpoints (files vs core API)",
      "kind": "Duplicate code",
      "files": [
        {
          "path": "files/v0/v0.go"
        },
        {
          "path": "files/v0/files.go"
        },
        {
          "path": "common/api/api.go"
        }
      ],
      "short_description": "**Goal**: Reduce bespoke HTTP plumbing for the files service and align streaming/error behavior with the rest of the API.\n\n**Why it matters**\n- The core API and logs services already use `common/api` helpers to register JSON and streaming endpoints, including consistent error handling.\n- The files service (`files/v0`) implements its own handler registration and error->status mapping because it streams raw/binary data.\n- This leads to:\n  - Duplicated handler-wrapper code\n  - Special-case error mapping logic for blobs vs store errors\n  - Harder to enforce a consistent API surface and logging.\n\n**Scope & files**\n- Files service custom wrappers:\n  - `files/v0/v0.go`\n    - `registerWorkloadCreateRouteHandler(...)`\n    - `registerFilesGetRouteHandler(...)`\n    - `sendErrorResponse(w, r, err)` (custom blob error mapping).\n  - `files/v0/files.go`\n    - Handlers like `HeadProjectFile`, `PutProjectFile`, `GetOrganizationFile`, `deChunkFile`, `copyBlob`, `copyOpenBlob` directly manipulate response bodies/headers.\n- Central helpers:\n  - `common/api/api.go`\n    - `RegisterHandler[...]`, `RegisterBodylessStreamHandler[...]`, `SendErrorResponse`, etc.\n\n**Concrete actions**\n1. **Extend `common/api` to support raw/streaming handlers**\n   - Add a new helper, for example in `common/api/streaming.go`:\n     ```go\n     type RawHandler func(ctx context.Context, w http.ResponseWriter, r *http.Request) error\n\n     func RegisterRawHandler(mux Mux, route string, method string, handler RawHandler) {\n       // Wraps RawHandler in the same error-handling and middleware that JSON handlers use,\n       // but leaves body streaming up to the handler.\n     }\n     ```\n   - Optionally support a `RegisterStreamHandler` variant that takes a function returning `(io.ReadCloser, headers map[string]string, error)`.\n\n2. **Centralize blob/storage error mapping**\n   - In `common/api/errors.go`, add a helper that normalizes store/blob errors:\n     ```go\n     func MapStorageError(err error) error {\n       switch {\n       case blobs.IsNotFound(err) || store.IsNotFound(err):\n         return WithHTTPCode(http.StatusNotFound, err)\n       case blobs.IsBadRequest(err):\n         return WithHTTPCode(http.StatusBadRequest, err)\n       default:\n         return err\n       }\n     }\n     ```\n   - Have `SendErrorResponse` (or the new RawHandler wrapper) call `MapStorageError` before encoding the response.\n\n3. **Refactor files service registration**\n   - In `files/v0/v0.go`, replace custom `registerWorkloadCreateRouteHandler` / `registerFilesGetRouteHandler` with calls to `RegisterRawHandler`.\n   - Remove `sendErrorResponse` and rely on `common/api.SendErrorResponse` plus `MapStorageError`.\n\n4. **Simplify files handlers**\n   - Keep `HeadProjectFile`, `PutProjectFile`, `GetOrganizationFile`, `deChunkFile`, `copyBlob`, `copyOpenBlob` focused on business logic:\n     - Parameter validation\n     - Interaction with `h.blobs` and chunking\n   - Let `RegisterRawHandler` and `SendErrorResponse` handle response headers and error responses.\n\n5. **Regression tests**\n   - Ensure existing `files/v0/*_test.go` coverage still passes after refactor.\n   - Add a couple of new tests to verify that blob-not-found errors return HTTP 404 and invalid input returns HTTP 400 consistently.\n\n**Kind**: Duplicate code",
      "recommended_action": ""
    },
    {
      "title": "Add unit tests for HTTP server wiring and middleware (api/files/common/server/common/middleware)",
      "kind": "Test coverage",
      "files": [
        {
          "path": "api/api.go"
        },
        {
          "path": "files/files.go"
        },
        {
          "path": "common/middleware"
        },
        {
          "path": "common/server/server.go"
        }
      ],
      "short_description": "**Goal**: Increase confidence in the HTTP plumbing (server setup, middleware, readiness, panic handling) which is currently lightly tested compared to its importance.\n\n**Why it matters**\n- The main servers and middleware orchestrate:\n  - Route registration and handler chains\n  - Auth, logging, CORS, panic recovery\n  - Health/readiness endpoints and graceful shutdown\n- Regressions here can take the entire service down or subtly change behavior without failing compile-time checks.\n\n**Scope & targets**\n- `api/api.go`\n  - e.g. `NewServer(...)` wiring routes and middleware.\n- `files/files.go`\n  - e.g. `NewServer(...)` for the files service.\n- `common/middleware`\n  - `cors.go`, `healthz.go`, `logger.go`, `middleware.go`, `panic.go`, `path_value_annotator.go`, `readyz.go` (auth middleware already has tests).\n- `common/server/server.go`\n  - `Serve(...)` manages signal handling and readiness.\n\n**Concrete actions**\n1. **Test `api.NewServer` wiring**\n   - Create `api/api_test.go`:\n     - Build a server with test implementations of Auth/IAM/Store/KMS.\n     - Use `httptest.NewServer` to send a simple request to a known route (e.g. `/v0/token`):\n       - Assert correct status code and basic behavior (e.g. auth required or not, depending on route).\n       - Assert middleware ordering where observable (e.g. CORS headers present, path values annotated for logging).\n\n2. **Test `files.NewServer` wiring**\n   - Create `files/files_test.go`:\n     - Construct the files server with fake blobs and store implementations.\n     - Hit a simple route (e.g. HEAD/PUT project file) and assert HTTP status and response headers (particularly CORS/Content-Type).\n\n3. **Add middleware unit tests**\n   - In `common/middleware`:\n     - `panic_test.go`: wrap a handler that panics, assert 500 response and log entry.\n     - `cors_test.go`: assert CORS headers for allowed origins and correct handling of OPTIONS preflight.\n     - `readyz_test.go` and `healthz_test.go`: set readiness flags and assert responses on `/readyz` and `/healthz`.\n     - `path_value_annotator_test.go`: ensure path variables are correctly attached to context/log fields.\n     - `logger_test.go`: verify it logs request method/path and doesn\u2019t alter status codes.\n\n4. **Test `common/server.Serve` behavior (as feasible)**\n   - Introduce an interface or function parameter for HTTP server startup so it can be swapped in tests.\n   - In `common/server/server_test.go`:\n     - Simulate graceful shutdown by sending a cancel signal.\n     - Assert that readiness is set to false on shutdown and that errors from the underlying server are propagated.\n\n5. **Run `go test ./...`**\n   - Ensure the new tests pass and don\u2019t introduce flakes.\n\n**Kind**: Test coverage",
      "recommended_action": ""
    },
    {
      "title": "Improve test coverage for `common/model` types and JSON/validation behavior",
      "kind": "Test coverage",
      "files": [
        {
          "path": "common/model/checkpoint.go"
        },
        {
          "path": "common/model/cluster.go"
        },
        {
          "path": "common/model/group.go"
        },
        {
          "path": "common/model/invitation.go"
        },
        {
          "path": "common/model/manifest.go"
        },
        {
          "path": "common/model/model.go"
        },
        {
          "path": "common/model/organization.go"
        },
        {
          "path": "common/model/project.go"
        },
        {
          "path": "common/model/refresh_token.go"
        },
        {
          "path": "common/model/service_account.go"
        },
        {
          "path": "common/model/task.go"
        },
        {
          "path": "common/model/timestamp.go"
        },
        {
          "path": "common/model/workload.go"
        }
      ],
      "short_description": "**Goal**: Ensure core domain models serialize/deserialize and validate correctly, preventing subtle bugs across services.\n\n**Why it matters**\n- `common/model` defines key entities (workloads, tasks, projects, organizations, tokens, checkpoints, etc.) used across the API, operator, scheduler, SDK, and frontend.\n- There are currently no tests dedicated to this package, despite its central role.\n\n**Scope & files**\n- `common/model/*` such as:\n  - `checkpoint.go`, `cluster.go`, `group.go`, `invitation.go`, `manifest.go`, `model.go`, `organization.go`, `project.go`, `refresh_token.go`, `service_account.go`, `task.go`, `timestamp.go`, `workload.go`.\n\n**Concrete actions**\n1. **Add a `common/model/model_test.go` (and split by topic if needed)**\n   - For each major type (e.g. `Workload`, `Task`, `Project`, `Organization`, `RefreshToken`):\n     - Construct a sample instance with non-trivial values.\n     - Marshal to JSON and unmarshal back.\n     - Assert fields are preserved and any custom field handling works as expected (e.g. timestamps, enums).\n\n2. **Test helper/validation methods**\n   - Identify any functions on these types that perform validation or conversions (e.g. from string IDs to typed refs, or tag parsing).\n   - Add tests covering:\n     - Happy path\n     - Invalid inputs raise the right errors or are rejected.\n\n3. **Add regression tests for known tricky fields**\n   - E.g., anything involving `time.Time`, custom timestamp types, or optional vs required fields.\n\n4. **Run `go test ./common/model` and then `go test ./...`**\n   - Ensure everything passes and coverage is significantly improved.\n\n**Kind**: Test coverage",
      "recommended_action": ""
    },
    {
      "title": "Introduce frontend test infrastructure and cover `frontend/lib/api/client.ts` and streaming client",
      "kind": "Test coverage",
      "files": [
        {
          "path": "frontend/package.json"
        },
        {
          "path": "frontend/lib/api/client.ts"
        },
        {
          "path": "frontend/lib/streaming/client.ts"
        }
      ],
      "short_description": "**Goal**: Make the frontend\u2019s primary API and streaming logic testable and add initial coverage.\n\n**Why it matters**\n- `frontend/lib/api/client.ts` and `frontend/lib/streaming/client.ts` contain complex logic (auth token retrieval, streaming reconnection, date conversions), but there is currently no test framework configured and no tests.\n- Changes to backend APIs or auth behavior are easy to break without test coverage.\n\n**Scope & files**\n- `frontend/package.json`\n- `frontend/lib/api/client.ts`\n- `frontend/lib/streaming/client.ts`\n\n**Concrete actions**\n1. **Add a test runner and basic configuration**\n   - In `frontend/package.json`, add devDependencies and scripts, e.g. using Vitest:\n     ```json\n     \"devDependencies\": {\n       \"vitest\": \"^x.y.z\",\n       \"@testing-library/react\": \"^x.y.z\",\n       \"@testing-library/dom\": \"^x.y.z\",\n       \"msw\": \"^x.y.z\"\n     },\n     \"scripts\": {\n       \"test\": \"vitest\"\n     }\n     ```\n   - Add a basic `vitest.config.ts` if needed.\n\n2. **Extract an injectable auth token provider**\n   - In `frontend/lib/api/client.ts` and `frontend/lib/streaming/client.ts`:\n     - Replace direct calls to `auth.currentUser.getIdToken(true)` with an injected function, e.g.:\n       ```ts\n       type TokenProvider = () => Promise<string | null>;\n\n       const defaultTokenProvider: TokenProvider = async () => {\n         const user = auth.currentUser;\n         return user ? user.getIdToken(true) : null;\n       };\n\n       class VolaryAPIClient {\n         constructor(private getToken: TokenProvider = defaultTokenProvider) {}\n         // ... use this.getToken() ...\n       }\n       ```\n     - Update streaming client similarly.\n\n3. **Add unit tests for `api/client.ts`**\n   - Create `frontend/lib/api/client.test.ts`:\n     - Mock `fetch` with a simple fake.\n     - Mock the token provider to return a known token.\n     - Test `rawRequest` / `request`:\n       - Success path: 200 JSON, verify body parsing.\n       - 204 No Content: ensure it doesn\u2019t try to parse JSON.\n       - 4xx/5xx: ensure errors are raised with appropriate message/shape.\n     - Test one or two higher-level functions (e.g. `getWorkloadEvents`) using a mocked response shape.\n\n4. **Add unit tests for streaming client**\n   - Create `frontend/lib/streaming/client.test.ts`:\n     - Use a helper that returns a `Response`-like object with a mocked `ReadableStream` (can be implemented with Web Streams API available in Node 18+ or a small polyfill).\n     - Test:\n       - JSONL parsing of multiple events.\n       - Handling of parse errors (should log and continue, not crash).\n       - Reconnection behavior based on `onStreamLifecycle` return values.\n\n5. **Update docs**\n   - Document in `README.md` under `frontend/` how to run tests (`npm test`) and any Node version requirements (e.g. Node >= 18 for Web Streams).\n\n**Kind**: Test coverage",
      "recommended_action": ""
    },
    {
      "title": "Implement reconnection filtering in `watchWorkloadCheckpoints` and add tests",
      "kind": "TODOs in the codebase",
      "files": [
        {
          "path": "frontend/lib/api/client.ts"
        }
      ],
      "short_description": "**Goal**: Make checkpoint streaming resilient to reconnects by avoiding duplicate events, completing an existing TODO in the client.\n\n**Why it matters**\n- `watchWorkloadCheckpoints` currently reconnects without filtering on last update time, unlike some other watchers that use `after`/timestamp-based filters.\n- This can cause duplicate checkpoint events after reconnections and is identified by an explicit TODO.\n\n**Scope & files**\n- `frontend/lib/api/client.ts`\n  - Method: `async watchWorkloadCheckpoints(...)` (near lines 720\u2013736).\n\n**Concrete actions**\n1. **Implement dynamic query params based on last updated timestamp**\n   - Modify `watchWorkloadCheckpoints`:\n     - Track the last checkpoint `update_time` (or equivalent timestamp field) in a local variable.\n     - Change the streaming config from static `queryParams` to a `getDynamicQueryParams` callback, similar to `watchWorkloadEvents`:\n       ```ts\n       let lastUpdated: string | null = null;\n\n       return streamingClient.watchStream<Checkpoint>({\n         baseUrl: `${API_BASE_URL}/v0/projects/${projectId}/checkpoints`,\n         queryParams: { parent: `projects/${projectId}/workloads/${workloadId}` },\n         getDynamicQueryParams: () =>\n           lastUpdated ? { after: lastUpdated } : {},\n       }, (checkpoint) => {\n         const converted = this.convertDates(checkpoint);\n         lastUpdated = converted.update_time?.toISOString?.() ?? lastUpdated;\n         onCheckpoint(converted);\n       }, onError);\n       ```\n     - Ensure the server supports an `after` query param; if not, coordinate with the backend or adapt to the agreed filter parameter.\n\n2. **Add tests**\n   - In `frontend/lib/api/client.test.ts`:\n     - Mock `streamingClient.watchStream` to capture the config passed in.\n     - Simulate receiving a few checkpoints, ensure `getDynamicQueryParams` returns `{ after: <lastTimestamp> }` after the first event.\n     - Assert `onCheckpoint` is called with converted date objects.\n\n3. **Verify backend compatibility**\n   - Confirm that the API endpoint used by `watchWorkloadCheckpoints` already supports `after=` filtering, or open a backend ticket if it does not.\n\n**Kind**: TODOs in the codebase",
      "recommended_action": ""
    },
    {
      "title": "Re-evaluate custom HTTP `WATCH` method and streaming compatibility in frontend streaming client",
      "kind": "Non-standard/antipatterns",
      "files": [
        {
          "path": "frontend/lib/streaming/client.ts"
        }
      ],
      "short_description": "**Goal**: Ensure the streaming approach is robust across browsers and aligns with server CORS/HTTP semantics.\n\n**Why it matters**\n- The streaming client uses a non-standard HTTP method (`WATCH`) plus custom headers (`Authorization`, `Accept: application/jsonl`) with `fetch` + `ReadableStream`.\n- Risks:\n  - Some environments or proxies may not support or may block unknown methods.\n  - Cross-origin requests with custom methods and headers require correct CORS preflight configuration.\n  - Some browsers/test environments may lack full `ReadableStream` support, leading to runtime errors.\n\n**Scope & files**\n- `frontend/lib/streaming/client.ts`\n  - Default method and streaming implementation using `fetch` and `response.body.getReader()`.\n\n**Concrete actions**\n1. **Confirm server-side support and CORS configuration**\n   - Verify that the API gateway or HTTP server allows:\n     - The `WATCH` method.\n     - CORS preflight for `WATCH` with `Authorization` and `Accept` headers.\n   - If this is fragile or non-standard for infra, consider:\n     - Switching to `GET` with a query parameter (e.g. `?watch=true`) or using Server-Sent Events (SSE) while keeping `WATCH` as an internal detail if needed.\n\n2. **Add feature detection and fallback**\n   - In `streaming/client.ts`, before using `response.body.getReader()`:\n     - Check for `response.body` and `response.body.getReader`.\n     - If missing, either:\n       - Reject with a clear error recommending a modern browser, or\n       - Provide a configurable fallback (e.g. polling) if required.\n\n3. **Document method usage**\n   - Document in a developer-facing doc (e.g. `docs/streaming.md`) that:\n     - The client uses `WATCH` by default.\n     - The server must be configured accordingly for CORS.\n     - Browser requirements for streaming (e.g. support for ReadableStream).\n\n4. **Add tests around behavior when streaming is unavailable**\n   - Extend streaming client tests to cover the case where `response.body` is undefined or `getReader` is missing.\n   - Ensure the client fails with a clear, testable error message.\n\n**Kind**: Non-standard/antipatterns",
      "recommended_action": ""
    },
    {
      "title": "Gradually re-enable `errcheck` in golangci-lint and fix unchecked errors",
      "kind": "Build and lint warnings",
      "files": [
        {
          "path": ".golangci.yml"
        }
      ],
      "short_description": "**Goal**: Catch and fix unchecked errors in Go code, which are currently being ignored by lint configuration.\n\n**Why it matters**\n- `.golangci.yml` explicitly disables `errcheck`, meaning calls that return an error can be silently ignored without warning.\n- In a codebase with network, storage, and cryptographic operations, unchecked errors can cause subtle and serious bugs.\n\n**Scope & files**\n- `.golangci.yml`\n  - `linters.disable: - errcheck`.\n- Entire Go codebase where errors are returned but not checked.\n\n**Concrete actions**\n1. **Run `errcheck` locally to assess impact**\n   - Temporarily enable `errcheck` by editing `.golangci.yml`:\n     ```yaml\n     linters:\n       disable:\n         # - errcheck  # comment this out temporarily\n     ```\n   - Run `golangci-lint run` and capture the list of failures.\n\n2. **Prioritize and fix the highest-risk unchecked errors**\n   - Focus first on:\n     - I/O operations (`io.Copy`, `Write`, `Close`), network calls, and external service calls (GCS, Firestore, HTTP clients).\n     - Security-sensitive operations (JWT verification, KMS, encryption/decryption).\n   - For each, either:\n     - Handle the error properly (return it, log and return, or retry), or\n     - If truly ignorable, explicitly document it and use `_ = ...` or a comment to make the choice clear.\n\n3. **Enable `errcheck` with selective exclusions if necessary**\n   - Once the most important unchecked errors are addressed, re-enable `errcheck` in `.golangci.yml`:\n     ```yaml\n     linters:\n       disable:\n         # remove errcheck from here\n       enable:\n         - errcheck\n     ```\n   - If there are a few legitimate noisy cases, use `//nolint:errcheck` with a brief justification rather than globally disabling the linter.\n\n4. **Add to CI**\n   - Ensure `make lint` / `golangci-lint run` runs in CI so new unchecked errors are caught on PRs.\n\n**Kind**: Build and lint warnings",
      "recommended_action": ""
    },
    {
      "title": "Add tests or refactor thinly-tested Go helper packages (logs/logging, common/openapi, common/flags, common/exec, sdk helpers)",
      "kind": "Test coverage",
      "files": [
        {
          "path": "logs/logging/logging.go"
        },
        {
          "path": "common/openapi/openapi.go"
        },
        {
          "path": "common/flags/flags.go"
        },
        {
          "path": "common/exec/exec.go"
        },
        {
          "path": "common/seed/seed.go"
        },
        {
          "path": "sdk/helm/helm.go"
        },
        {
          "path": "sdk/output/output.go"
        },
        {
          "path": "sdk/progress/ui.go"
        },
        {
          "path": "sdk/progress/winch_other.go"
        },
        {
          "path": "sdk/progress/winch_windows.go"
        }
      ],
      "short_description": "**Goal**: Improve reliability of helper packages that are used widely but have little or no direct tests.\n\n**Why it matters**\n- Several helper packages are used across the codebase but lack tests despite containing non-trivial logic.\n- Bugs here can propagate widely and are hard to diagnose.\n\n**Scope & candidate packages**\n- `logs/logging/logging.go`\n- `common/openapi/openapi.go`\n- `common/flags/flags.go`\n- `common/exec/exec.go`\n- `common/seed/seed.go`\n- `sdk/helm/helm.go`\n- `sdk/output/output.go`\n- `sdk/progress/ui.go`, `sdk/progress/winch_other.go`, `sdk/progress/winch_windows.go`\n\n**Concrete actions**\n1. **For each package, assess and create at least one focused test file**\n   - `logs/logging`:\n     - Test that log helpers format messages as expected and propagate context/fields correctly using a custom sink or in-memory logger.\n   - `common/openapi`:\n     - Test that generating docs for a small set of example routes yields expected paths and schemas.\n   - `common/flags`:\n     - Test parsing and defaulting behavior for representative flags, including error cases.\n   - `common/exec`:\n     - Test command construction and error handling using a noop command or injecting a fake runner.\n   - `sdk/helm`:\n     - Test chart-path resolution or any logic transforming Helm values/config.\n   - `sdk/output`:\n     - Test formatting functions to ensure stable, user-friendly output.\n   - `sdk/progress`:\n     - Test internal state changes of progress UI logic (not the actual terminal side effects) using a fake writer.\n\n2. **Run tests and iterate**\n   - Add these tests incrementally, running `go test ./...` after each small batch to avoid large refactors.\n\n**Kind**: Test coverage",
      "recommended_action": ""
    },
    {
      "title": "Implement HTTP Range support for chunked file downloads in files service",
      "kind": "TODOs in the codebase",
      "files": [
        {
          "path": "files/v0/files.go"
        }
      ],
      "short_description": "**Goal**: Allow clients to resume large file downloads instead of restarting from scratch.\n\n**Why it matters**\n- The files service supports chunked storage, but `deChunkFile` currently streams all chunks sequentially without respect to `Range` headers.\n- There is an explicit TODO to support Range requests for resumed downloads.\n\n**Scope & files**\n- `files/v0/files.go`\n  - Function `deChunkFile(...)` with TODO about supporting Range.\n\n**Concrete actions**\n1. **Design Range-handling behavior**\n   - Decide on how Range interacts with chunked storage:\n     - Likely map byte ranges to underlying chunk offsets using metadata from `chunk.AllChunks`.\n\n2. **Implement Range parsing and validation**\n   - In `GetOrganizationFile`/`deChunkFile`:\n     - Parse the `Range` header if present.\n     - Validate it (single range only to start; respond with 416 if invalid/out of bounds).\n\n3. **Map requested range to chunks**\n   - Use `chunk.AllChunks` output to determine which chunks intersect the requested range and which byte ranges within each chunk should be read.\n   - Adjust calls to `copyBlob` or a new helper to read partial content when necessary.\n\n4. **Set appropriate response headers**\n   - When serving partial content:\n     - Set `StatusPartialContent (206)`.\n     - Set `Content-Range` and `Accept-Ranges: bytes`.\n\n5. **Add tests**\n   - In `files/v0/files_test.go`:\n     - Use a fake blob store returning known chunk content.\n     - Test full download vs partial download and resume behavior.\n\n**Kind**: TODOs in the codebase",
      "recommended_action": ""
    },
    {
      "title": "Fill in missing description for 'Roles' section in frontend OpenAPI spec",
      "kind": "TODOs in the codebase",
      "files": [
        {
          "path": "frontend/openapi.yaml"
        }
      ],
      "short_description": "**Goal**: Complete the frontend OpenAPI documentation for the Roles section and remove stale TODOs in docs.\n\n**Why it matters**\n- `frontend/openapi.yaml` contains a TODO for the Roles tag with an empty description.\n- This affects generated docs and client understanding of the Roles-related endpoints.\n\n**Scope & files**\n- `frontend/openapi.yaml`\n  - Lines around the `Roles` tag currently show a TODO and `description: ''`.\n\n**Concrete actions**\n1. **Define the Roles feature description**\n   - Clarify what the Roles endpoints do (e.g., managing IAM-like role definitions, listing roles, etc.).\n   - Replace the TODO block:\n     ```yaml\n     # TODO: fill in\n     - name: Roles\n       description: ''\n       x-path-components:\n         - roles\n     ```\n     with a proper description, e.g.:\n     ```yaml\n     - name: Roles\n       description: |\n         Operations to list and manage roles within an organization, such as predefined and custom roles\n         that control permissions for users and service accounts.\n       x-path-components:\n         - roles\n     ```\n\n2. **Run any OpenAPI validation or generation tools**\n   - If there are scripts that generate clients or validate OpenAPI (e.g. `go test ./frontend/...` or a custom generator), run them to ensure the updated spec is valid.\n\n3. **Remove or update related TODO comments**\n   - Ensure any doc-related TODOs that are now resolved are removed to keep the spec clean.\n\n**Kind**: TODOs in the codebase",
      "recommended_action": ""
    }
  ]
}